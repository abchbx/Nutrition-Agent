import numpy as np
from typing import Dict, Any, Type
from langchain_core.tools import BaseTool
from langchain_core.prompts import PromptTemplate
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.docstore import InMemoryDocstore
from langchain_core.documents import Document
from langchain_community.vectorstores import FAISS
# --- ä¿®æ”¹å¼€å§‹ï¼šå¯¼å…¥å¿…è¦çš„æ¨¡å— ---
from langchain_community.docstore import InMemoryDocstore
from faiss import IndexIVFPQ, IndexFlatL2
# --- ä¿®æ”¹ç»“æŸ ---
from config import AGENT_MODEL, AGENT_TEMPERATURE, EMBEDDING_MODEL
from pydantic import BaseModel, Field
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import AGENT_MODEL, AGENT_TEMPERATURE

class NutritionQAInput(BaseModel):
    """è¥å…»å­¦é—®ç­”å·¥å…·è¾“å…¥æ¨¡å‹"""
    question: str = Field(description="è¥å…»å­¦ç›¸å…³é—®é¢˜")
    detail_level: str = Field(default="ä¸­ç­‰", description="å›ç­”è¯¦ç»†ç¨‹åº¦ï¼šç®€å•ã€ä¸­ç­‰ã€è¯¦ç»†")

class NutritionQATool(BaseTool):
    """è¥å…»å­¦çŸ¥è¯†é—®ç­”å·¥å…·"""
    name: str = "nutrition_qa"
    description: str = "å›ç­”è¥å…»å­¦ç›¸å…³çš„çŸ¥è¯†é—®é¢˜ï¼ŒåŒ…æ‹¬è¥å…»åŸç†ã€å¥åº·é¥®é£Ÿã€è¥å…»ç´ åŠŸèƒ½ç­‰"
    args_schema: Type[BaseModel] = NutritionQAInput

    llm: Any = None
    embeddings: Any = None
    knowledge_base: Any = None
    qa_prompt: Any = None
    qa_chain: Any = None

    # --- å…³é”®ä¿®å¤ 1ï¼šä¿®æ”¹æ„é€ å‡½æ•°ä»¥æ¥æ”¶å…±äº«çš„ embedding æ¨¡å‹ ---
    def __init__(self, embeddings: HuggingFaceEmbeddings):
        super().__init__()
        self.llm = ChatOpenAI(
            model_name=AGENT_MODEL,
            temperature=AGENT_TEMPERATURE
        )
        # ä½¿ç”¨ä»å¤–éƒ¨ä¼ å…¥çš„ã€å·²ç»åŠ è½½å¥½çš„æ¨¡å‹å®ä¾‹
        self.embeddings = embeddings
        self.knowledge_base = self._create_knowledge_base()

        self.qa_prompt = PromptTemplate(
            input_variables=["question", "context", "detail_level"],
            template="""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¥å…»å­¦ä¸“å®¶ï¼Œè¯·æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{question}

ç›¸å…³è¥å…»å­¦çŸ¥è¯†ï¼š
{context}

å›ç­”è¯¦ç»†ç¨‹åº¦è¦æ±‚ï¼š{detail_level}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œæä¾›ä¸“ä¸šã€å‡†ç¡®ã€æ˜“æ‡‚çš„å›ç­”ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¿¡æ¯ä¸è¶³ä»¥å®Œå…¨å›ç­”é—®é¢˜ï¼Œè¯·ç»“åˆä½ çš„ä¸“ä¸šçŸ¥è¯†è¿›è¡Œè¡¥å……ã€‚

å›ç­”è¦æ±‚ï¼š
1. ç§‘å­¦å‡†ç¡®ï¼ŒåŸºäºè¥å…»å­¦åŸç†
2. å®ç”¨æ€§å¼ºï¼Œèƒ½æŒ‡å¯¼å®é™…ç”Ÿæ´»
3. è¯­è¨€é€šä¿—æ˜“æ‡‚ï¼Œé¿å…è¿‡å¤šä¸“ä¸šæœ¯è¯­
4. æ ¹æ®è¯¦ç»†ç¨‹åº¦è¦æ±‚è°ƒæ•´å›ç­”æ·±åº¦
5. å¦‚æœ‰å¿…è¦ï¼Œæä¾›å…·ä½“çš„æ•°æ®å’Œä¾‹å­

---
**æ ¼å¼è¦æ±‚ï¼š**
è¯·ä½¿ç”¨Markdownæ ¼å¼è¿›è¡Œæ’ç‰ˆï¼Œä»¥æé«˜å¯è¯»æ€§ã€‚å¯ä»¥ä½¿ç”¨æ ‡é¢˜ï¼ˆå¦‚ '##'ï¼‰ã€è¦ç‚¹ï¼ˆå¦‚ '*' æˆ– '-'ï¼‰å’Œç²—ä½“ï¼ˆå¦‚ '**é‡ç‚¹**'ï¼‰æ¥ç»„ç»‡ä½ çš„å›ç­”ã€‚
"""
        )
        self.qa_chain = self.qa_prompt | self.llm


    def _create_knowledge_base(self) -> FAISS:
        nutrition_docs = [
            Document(page_content="å®é‡è¥å…»ç´ åŒ…æ‹¬ç¢³æ°´åŒ–åˆç‰©ã€è›‹ç™½è´¨å’Œè„‚è‚ªï¼Œæ˜¯èº«ä½“èƒ½é‡çš„ä¸»è¦æ¥æºã€‚", metadata={"category": "å®é‡è¥å…»ç´ ", "topic": "åŸºç¡€"}),
            Document(page_content="è›‹ç™½è´¨æ˜¯æ„æˆè‚Œè‚‰ã€å™¨å®˜å’Œé…¶çš„åŸºç¡€ï¼Œå¯¹äºç”Ÿé•¿å’Œä¿®å¤è‡³å…³é‡è¦ã€‚", metadata={"category": "å®é‡è¥å…»ç´ ", "topic": "è›‹ç™½è´¨"}),
            Document(page_content="è†³é£Ÿçº¤ç»´æœ‰åŠ©äºè‚ é“å¥åº·ï¼Œèƒ½å¢åŠ é¥±è…¹æ„Ÿï¼Œå¸¸è§äºè”¬èœã€æ°´æœå’Œå…¨è°·ç‰©ä¸­ã€‚", metadata={"category": "å…¶ä»–è¥å…»ç´ ", "topic": "è†³é£Ÿçº¤ç»´"}),
        ]
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        texts = text_splitter.split_documents(nutrition_docs)

        try:
            print("ğŸ’¡ æ­£åœ¨ä¸ºQAå·¥å…·åˆ›å»ºçŸ¥è¯†åº“ (ä½¿ç”¨ IndexFlatL2)...")
            
            embeddings_vectors = self.embeddings.embed_documents([doc.page_content for doc in texts])
            vectors = np.array(embeddings_vectors, dtype=np.float32)
            embedding_dimension = vectors.shape[1]
            
            # --- ã€æ ¸å¿ƒä¿®æ­£ã€‘åŒæ ·ä½¿ç”¨ IndexFlatL2 ---
            index = IndexFlatL2(embedding_dimension)
            index.add(vectors)

            docstore = InMemoryDocstore({str(i): doc for i, doc in enumerate(texts)})
            index_to_docstore_id = {i: str(i) for i in range(len(texts))}

            knowledge_base = FAISS(
                embedding_function=self.embeddings.embed_query,
                index=index,
                docstore=docstore,
                index_to_docstore_id=index_to_docstore_id
            )

            print("âœ… QAå·¥å…·çŸ¥è¯†åº“åˆ›å»ºæˆåŠŸ!")
            return knowledge_base
        
        except Exception as e:
            print(f"âŒ åˆ›å»ºQAçŸ¥è¯†åº“æ—¶å‡ºé”™: {e}")
            # åœ¨è¿™ç§ç®€å•æ¨¡å¼ä¸‹ï¼Œå¦‚æœè¿˜å‡ºé”™ï¼Œç›´æ¥ä½¿ç”¨æ›´ä¸Šå±‚çš„å‡½æ•°
            return FAISS.from_documents(texts, self.embeddings)
    def _run(self, question: str, detail_level: str = "ä¸­ç­‰") -> str:
        try:
            relevant_docs = self.knowledge_base.similarity_search(question, k=3)
            context = "\n\n".join(doc.page_content for doc in relevant_docs)
            if not context:
                context = "æœªæ‰¾åˆ°ç›¸å…³çš„è¥å…»å­¦çŸ¥è¯†æ–‡æ¡£ï¼Œå°†åŸºäºä¸“ä¸šçŸ¥è¯†å›ç­”ã€‚"

            response = self.qa_chain.invoke({
                "question": question,
                "context": context,
                "detail_level": detail_level
            })
            answer = response.content

            result = f"ğŸ“š è¥å…»å­¦çŸ¥è¯†é—®ç­”ï¼š\n"
            result += f"â“ é—®é¢˜ï¼š{question}\n"
            result += f"ğŸ“ è¯¦ç»†ç¨‹åº¦ï¼š{detail_level}\n\n"
            result += "ğŸ’¡ å›ç­”ï¼š\n"
            result += "=" * 50 + "\n"
            result += answer

            if relevant_docs:
                result += "\n\n" + "=" * 50 + "\n"
                result += "ğŸ“– å‚è€ƒæ¥æºï¼š\n"
                for i, doc in enumerate(relevant_docs, 1):
                    result += f"{i}. {doc.metadata.get('category', 'è¥å…»å­¦')} - {doc.metadata.get('topic', 'ç›¸å…³çŸ¥è¯†')}\n"
            return result
        except Exception as e:
            return f"å›ç­”è¥å…»å­¦é—®é¢˜æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

# --- ä¸‹é¢çš„ NutritionMythTool éƒ¨åˆ†ä¿æŒä¸å˜ ---

class NutritionMythInput(BaseModel):
    """è¥å…»è¯¯åŒºè¾¨æå·¥å…·è¾“å…¥æ¨¡å‹"""
    myth: str = Field(description="éœ€è¦è¾¨æçš„è¥å…»è¯¯åŒºæˆ–æµè¡Œè¯´æ³•")

class NutritionMythTool(BaseTool):
    """è¥å…»è¯¯åŒºè¾¨æå·¥å…·"""
    name: str = "nutrition_myth"
    description: str = "è¾¨æè¥å…»å­¦è¯¯åŒºå’Œæµè¡Œè¯´æ³•ï¼Œæä¾›ç§‘å­¦ä¾æ®"
    args_schema: Type[BaseModel] = NutritionMythInput

    llm: Any = None
    myth_prompt: Any = None
    myth_chain: Any = None

    def __init__(self):
        super().__init__()
        self.llm = ChatOpenAI(
            model_name=AGENT_MODEL,
            temperature=AGENT_TEMPERATURE
        )

        self.myth_prompt = PromptTemplate(
            input_variables=["myth"],
            template="""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¥å…»å­¦ä¸“å®¶ï¼Œä½ çš„ä»»åŠ¡æ˜¯è¾¨æä»¥ä¸‹è¥å…»è¯¯åŒºæˆ–æµè¡Œè¯´æ³•ã€‚

**è¯¯åŒº/è¯´æ³•ï¼š** {myth}

---
è¯·ä½¿ç”¨æ¸…æ™°çš„Markdownæ ¼å¼ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¿›è¡Œåˆ†æï¼Œæ¯ä¸ªéƒ¨åˆ†ä½¿ç”¨äºŒçº§æ ‡é¢˜ï¼ˆ##ï¼‰ï¼š

## ğŸ“– è¯´æ³•çš„æ¥æºä¸æµè¡Œç¨‹åº¦
* åœ¨è¿™é‡Œåˆ†æè¿™ä¸ªè¯´æ³•çš„èµ·æºï¼Œä»¥åŠå®ƒä¸ºä»€ä¹ˆä¼šæµè¡Œèµ·æ¥ã€‚

## ğŸ”¬ ç§‘å­¦äº‹å®ä¸ä¾æ®
* è¯·ä»ç§‘å­¦è§’åº¦å‡ºå‘ï¼Œåˆ—å‡ºä¸æ­¤è¯´æ³•ç›¸å…³çš„æ ¸å¿ƒäº‹å®å’Œç ”ç©¶è¯æ®ã€‚
* å¯ä»¥ä½¿ç”¨è¦ç‚¹æ¥ç½—åˆ—ï¼Œå¹¶å°† **å…³é”®è¯** åŠ ç²—ã€‚

## âœ… æ­£ç¡®æ€§ä¸å±€é™æ€§
* åˆ†æè¿™ä¸ªè¯´æ³•åœ¨å¤šå¤§ç¨‹åº¦ä¸Šæ˜¯æ­£ç¡®çš„ï¼Œä»¥åŠå®ƒçš„é€‚ç”¨èŒƒå›´å’Œå±€é™æ€§ã€‚
* ä¾‹å¦‚ï¼šå®ƒæ˜¯å¦åªåœ¨ç‰¹å®šæƒ…å†µä¸‹æˆç«‹ï¼Ÿ

## âš ï¸ å¯èƒ½çš„å±å®³æˆ–é£é™©
* å¦‚æœäººä»¬ç›²ç›®ç›¸ä¿¡å¹¶éµå¾ªè¿™ä¸ªè¯´æ³•ï¼Œå¯èƒ½ä¼šå¸¦æ¥å“ªäº›å¥åº·é£é™©æˆ–è´Ÿé¢å½±å“ï¼Ÿ

## ğŸ‘ ç§‘å­¦çš„å»ºè®®ä¸æ›¿ä»£æ–¹æ¡ˆ
* é’ˆå¯¹è¿™ä¸ªè¯¯åŒºï¼Œæä¾›ç§‘å­¦ã€å¯è¡Œçš„é¥®é£Ÿæˆ–ç”Ÿæ´»æ–¹å¼å»ºè®®ã€‚
* å¦‚æœåŸè¯´æ³•æœ‰å¯å–ä¹‹å¤„ï¼Œå¯ä»¥æå‡ºæ›´ç§‘å­¦çš„æ›¿ä»£æ–¹æ¡ˆã€‚
"""
        )
        self.myth_chain = self.myth_prompt | self.llm

    def _run(self, myth: str) -> str:
        try:
            response = self.myth_chain.invoke({"myth": myth})
            analysis = response.content
            
            result = f"ğŸ” è¥å…»è¯¯åŒºè¾¨æï¼š\n"
            result += f"ğŸ¤” è¯¯åŒºï¼š{myth}\n\n"
            result += "ğŸ“‹ ç§‘å­¦åˆ†æï¼š\n"
            result += "=" * 50 + "\n"
            result += analysis
            return result
        except Exception as e:
            return f"è¾¨æè¥å…»è¯¯åŒºæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"