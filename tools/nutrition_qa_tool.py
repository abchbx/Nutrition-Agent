from typing import Dict, Any, Type
from langchain_core.tools import BaseTool
from langchain_core.prompts import PromptTemplate
# æ¨èæ›´æ–°ï¼šä» langchain_openai å¯¼å…¥
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_community.vectorstores import FAISS
from config import AGENT_MODEL, AGENT_TEMPERATURE, EMBEDDING_MODEL 
from pydantic import BaseModel, Field
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import AGENT_MODEL, AGENT_TEMPERATURE

class NutritionQAInput(BaseModel):
    """è¥å…»å­¦é—®ç­”å·¥å…·è¾“å…¥æ¨¡å‹"""
    question: str = Field(description="è¥å…»å­¦ç›¸å…³é—®é¢˜")
    detail_level: str = Field(default="ä¸­ç­‰", description="å›ç­”è¯¦ç»†ç¨‹åº¦ï¼šç®€å•ã€ä¸­ç­‰ã€è¯¦ç»†")

class NutritionQATool(BaseTool):
    """è¥å…»å­¦çŸ¥è¯†é—®ç­”å·¥å…·"""
    name: str = "nutrition_qa"
    description: str = "å›ç­”è¥å…»å­¦ç›¸å…³çš„çŸ¥è¯†é—®é¢˜ï¼ŒåŒ…æ‹¬è¥å…»åŸç†ã€å¥åº·é¥®é£Ÿã€è¥å…»ç´ åŠŸèƒ½ç­‰"
    args_schema: Type[BaseModel] = NutritionQAInput
    
    # --- ä¿®å¤1ï¼šå£°æ˜æ‰€æœ‰å®ä¾‹å±æ€§å¹¶æä¾›é»˜è®¤å€¼ ---
    llm: Any = None
    embeddings: Any = None
    knowledge_base: Any = None
    qa_prompt: Any = None
    qa_chain: Any = None
    
    def __init__(self):
        super().__init__()
        self.llm = ChatOpenAI(
            model_name=AGENT_MODEL,
            temperature=AGENT_TEMPERATURE
        )
        self.embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)
        self.knowledge_base = self._create_knowledge_base()

        self.qa_prompt = PromptTemplate(
            input_variables=["question", "context", "detail_level"],
            template="""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¥å…»å­¦ä¸“å®¶ï¼Œè¯·æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{question}

ç›¸å…³è¥å…»å­¦çŸ¥è¯†ï¼š
{context}

å›ç­”è¯¦ç»†ç¨‹åº¦è¦æ±‚ï¼š{detail_level}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œæä¾›ä¸“ä¸šã€å‡†ç¡®ã€æ˜“æ‡‚çš„å›ç­”ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¿¡æ¯ä¸è¶³ä»¥å®Œå…¨å›ç­”é—®é¢˜ï¼Œè¯·ç»“åˆä½ çš„ä¸“ä¸šçŸ¥è¯†è¿›è¡Œè¡¥å……ã€‚

å›ç­”è¦æ±‚ï¼š
1. ç§‘å­¦å‡†ç¡®ï¼ŒåŸºäºè¥å…»å­¦åŸç†
2. å®ç”¨æ€§å¼ºï¼Œèƒ½æŒ‡å¯¼å®é™…ç”Ÿæ´»
3. è¯­è¨€é€šä¿—æ˜“æ‡‚ï¼Œé¿å…è¿‡å¤šä¸“ä¸šæœ¯è¯­
4. æ ¹æ®è¯¦ç»†ç¨‹åº¦è¦æ±‚è°ƒæ•´å›ç­”æ·±åº¦
5. å¦‚æœ‰å¿…è¦ï¼Œæä¾›å…·ä½“çš„æ•°æ®å’Œä¾‹å­

---
**æ ¼å¼è¦æ±‚ï¼š**
è¯·ä½¿ç”¨Markdownæ ¼å¼è¿›è¡Œæ’ç‰ˆï¼Œä»¥æé«˜å¯è¯»æ€§ã€‚å¯ä»¥ä½¿ç”¨æ ‡é¢˜ï¼ˆå¦‚ '##'ï¼‰ã€è¦ç‚¹ï¼ˆå¦‚ '*' æˆ– '-'ï¼‰å’Œç²—ä½“ï¼ˆå¦‚ '**é‡ç‚¹**'ï¼‰æ¥ç»„ç»‡ä½ çš„å›ç­”ã€‚
"""
        )
        # --- ä¿®å¤2ï¼šä½¿ç”¨æ–°çš„LCELè¯­æ³• (prompt | llm) ---
        self.qa_chain = self.qa_prompt | self.llm

    def _create_knowledge_base(self) -> FAISS:
        nutrition_docs = [
            Document(page_content="å®é‡è¥å…»ç´ åŒ…æ‹¬...", metadata={"category": "å®é‡è¥å…»ç´ ", "topic": "ç¢³æ°´åŒ–åˆç‰©"}),
            Document(page_content="è›‹ç™½è´¨æ˜¯ç”Ÿå‘½çš„åŸºç¡€...", metadata={"category": "å®é‡è¥å…»ç´ ", "topic": "è›‹ç™½è´¨"}),
            Document(page_content="è„‚è‚ªæ˜¯é‡è¦çš„èƒ½é‡å‚¨å­˜å½¢å¼...", metadata={"category": "å®é‡è¥å…»ç´ ", "topic": "è„‚è‚ª"}),
            Document(page_content="å¾®é‡è¥å…»ç´ åŒ…æ‹¬...", metadata={"category": "å¾®é‡è¥å…»ç´ ", "topic": "ç»´ç”Ÿç´ å’ŒçŸ¿ç‰©è´¨"}),
            Document(page_content="è†³é£Ÿçº¤ç»´æ˜¯ä¸èƒ½è¢«...", metadata={"category": "å…¶ä»–è¥å…»ç´ ", "topic": "è†³é£Ÿçº¤ç»´"}),
            Document(page_content="æ°´æ˜¯ç”Ÿå‘½å¿…éœ€çš„è¥å…»ç´ ...", metadata={"category": "å…¶ä»–è¥å…»ç´ ", "topic": "æ°´"}),
            Document(page_content="å¥åº·é¥®é£Ÿçš„åŸºæœ¬åŸåˆ™...", metadata={"category": "å¥åº·é¥®é£Ÿ", "topic": "åŸºæœ¬åŸåˆ™"}),
            Document(page_content="ä½“é‡ç®¡ç†çš„åŸºæœ¬åŸç†...", metadata={"category": "ä½“é‡ç®¡ç†", "topic": "çƒ­é‡å¹³è¡¡"}),
            Document(page_content="ä¸åŒç”Ÿå‘½é˜¶æ®µ...", metadata={"category": "ç‰¹æ®Šäººç¾¤", "topic": "ç”Ÿå‘½é˜¶æ®µè¥å…»"}),
            Document(page_content="è¿åŠ¨è¥å…»éœ€è¦æ ¹æ®...", metadata={"category": "è¿åŠ¨è¥å…»", "topic": "è¿åŠ¨ä¸è¥å…»"})
        ]

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        texts = text_splitter.split_documents(nutrition_docs)

        return FAISS.from_documents(texts, self.embeddings)

    def _run(self, question: str, detail_level: str = "ä¸­ç­‰") -> str:
        try:
            relevant_docs = self.knowledge_base.similarity_search(question, k=3)
            context = "\n\n".join(doc.page_content for doc in relevant_docs)
            if not context:
                context = "æœªæ‰¾åˆ°ç›¸å…³çš„è¥å…»å­¦çŸ¥è¯†æ–‡æ¡£ï¼Œå°†åŸºäºä¸“ä¸šçŸ¥è¯†å›ç­”ã€‚"

            # --- ä¿®å¤2ï¼šä½¿ç”¨ .invoke() ä»£æ›¿ .run()ï¼Œå¹¶ä¼ å…¥å­—å…¸ ---
            # .invoke() çš„è¿”å›å€¼ç›´æ¥å°±æ˜¯ä¸€ä¸ªå†…å®¹å¯¹è±¡ï¼Œæˆ‘ä»¬éœ€è¦æå–å…¶ .content å±æ€§
            response = self.qa_chain.invoke({
                "question": question,
                "context": context,
                "detail_level": detail_level
            })
            answer = response.content

            result = f"ğŸ“š è¥å…»å­¦çŸ¥è¯†é—®ç­”ï¼š\n"
            result += f"â“ é—®é¢˜ï¼š{question}\n"
            result += f"ğŸ“ è¯¦ç»†ç¨‹åº¦ï¼š{detail_level}\n\n"
            result += "ğŸ’¡ å›ç­”ï¼š\n"
            result += "=" * 50 + "\n"
            result += answer

            if relevant_docs:
                result += "\n\n" + "=" * 50 + "\n"
                result += "ğŸ“– å‚è€ƒæ¥æºï¼š\n"
                for i, doc in enumerate(relevant_docs, 1):
                    result += f"{i}. {doc.metadata.get('category', 'è¥å…»å­¦')} - {doc.metadata.get('topic', 'ç›¸å…³çŸ¥è¯†')}\n"
            return result
        except Exception as e:
            return f"å›ç­”è¥å…»å­¦é—®é¢˜æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

class NutritionMythInput(BaseModel):
    """è¥å…»è¯¯åŒºè¾¨æå·¥å…·è¾“å…¥æ¨¡å‹"""
    myth: str = Field(description="éœ€è¦è¾¨æçš„è¥å…»è¯¯åŒºæˆ–æµè¡Œè¯´æ³•")

class NutritionMythTool(BaseTool):
    """è¥å…»è¯¯åŒºè¾¨æå·¥å…·"""
    name: str = "nutrition_myth"
    description: str = "è¾¨æè¥å…»å­¦è¯¯åŒºå’Œæµè¡Œè¯´æ³•ï¼Œæä¾›ç§‘å­¦ä¾æ®"
    args_schema: Type[BaseModel] = NutritionMythInput

    # --- ä¿®å¤1ï¼šå£°æ˜æ‰€æœ‰å®ä¾‹å±æ€§å¹¶æä¾›é»˜è®¤å€¼ ---
    llm: Any = None
    myth_prompt: Any = None
    myth_chain: Any = None

    def __init__(self):
        super().__init__()
        self.llm = ChatOpenAI(
            model_name=AGENT_MODEL,
            temperature=AGENT_TEMPERATURE
        )

        self.myth_prompt = PromptTemplate(
            input_variables=["myth"],
            template="""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¥å…»å­¦ä¸“å®¶ï¼Œä½ çš„ä»»åŠ¡æ˜¯è¾¨æä»¥ä¸‹è¥å…»è¯¯åŒºæˆ–æµè¡Œè¯´æ³•ã€‚

**è¯¯åŒº/è¯´æ³•ï¼š** {myth}

---
è¯·ä½¿ç”¨æ¸…æ™°çš„Markdownæ ¼å¼ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¿›è¡Œåˆ†æï¼Œæ¯ä¸ªéƒ¨åˆ†ä½¿ç”¨äºŒçº§æ ‡é¢˜ï¼ˆ##ï¼‰ï¼š

## ğŸ“– è¯´æ³•çš„æ¥æºä¸æµè¡Œç¨‹åº¦
* åœ¨è¿™é‡Œåˆ†æè¿™ä¸ªè¯´æ³•çš„èµ·æºï¼Œä»¥åŠå®ƒä¸ºä»€ä¹ˆä¼šæµè¡Œèµ·æ¥ã€‚

## ğŸ”¬ ç§‘å­¦äº‹å®ä¸ä¾æ®
* è¯·ä»ç§‘å­¦è§’åº¦å‡ºå‘ï¼Œåˆ—å‡ºä¸æ­¤è¯´æ³•ç›¸å…³çš„æ ¸å¿ƒäº‹å®å’Œç ”ç©¶è¯æ®ã€‚
* å¯ä»¥ä½¿ç”¨è¦ç‚¹æ¥ç½—åˆ—ï¼Œå¹¶å°† **å…³é”®è¯** åŠ ç²—ã€‚

## âœ… æ­£ç¡®æ€§ä¸å±€é™æ€§
* åˆ†æè¿™ä¸ªè¯´æ³•åœ¨å¤šå¤§ç¨‹åº¦ä¸Šæ˜¯æ­£ç¡®çš„ï¼Œä»¥åŠå®ƒçš„é€‚ç”¨èŒƒå›´å’Œå±€é™æ€§ã€‚
* ä¾‹å¦‚ï¼šå®ƒæ˜¯å¦åªåœ¨ç‰¹å®šæƒ…å†µä¸‹æˆç«‹ï¼Ÿ

## âš ï¸ å¯èƒ½çš„å±å®³æˆ–é£é™©
* å¦‚æœäººä»¬ç›²ç›®ç›¸ä¿¡å¹¶éµå¾ªè¿™ä¸ªè¯´æ³•ï¼Œå¯èƒ½ä¼šå¸¦æ¥å“ªäº›å¥åº·é£é™©æˆ–è´Ÿé¢å½±å“ï¼Ÿ

## ğŸ‘ ç§‘å­¦çš„å»ºè®®ä¸æ›¿ä»£æ–¹æ¡ˆ
* é’ˆå¯¹è¿™ä¸ªè¯¯åŒºï¼Œæä¾›ç§‘å­¦ã€å¯è¡Œçš„é¥®é£Ÿæˆ–ç”Ÿæ´»æ–¹å¼å»ºè®®ã€‚
* å¦‚æœåŸè¯´æ³•æœ‰å¯å–ä¹‹å¤„ï¼Œå¯ä»¥æå‡ºæ›´ç§‘å­¦çš„æ›¿ä»£æ–¹æ¡ˆã€‚
"""
        )
        # --- ä¿®å¤2ï¼šä½¿ç”¨æ–°çš„LCELè¯­æ³• (prompt | llm) ---
        self.myth_chain = self.myth_prompt | self.llm

    def _run(self, myth: str) -> str:
        try:
            # --- ä¿®å¤2ï¼šä½¿ç”¨ .invoke() ä»£æ›¿ .run()ï¼Œå¹¶ä¼ å…¥å­—å…¸ ---
            response = self.myth_chain.invoke({"myth": myth})
            analysis = response.content
            
            result = f"ğŸ” è¥å…»è¯¯åŒºè¾¨æï¼š\n"
            result += f"ğŸ¤” è¯¯åŒºï¼š{myth}\n\n"
            result += "ğŸ“‹ ç§‘å­¦åˆ†æï¼š\n"
            result += "=" * 50 + "\n"
            result += analysis
            return result
        except Exception as e:
            return f"è¾¨æè¥å…»è¯¯åŒºæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"